{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: data/preprocessed_data/spectrogram/data_spectrogram_angle_0_train.json\n"
     ]
    }
   ],
   "source": [
    "from fetch_format_data import fetch_data\n",
    "\n",
    "df = fetch_data('spectrogram','0',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['filename','maps','split_id','genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>maps</th>\n",
       "      <th>split_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>[[575, 636, 546, 386, 302, 179, 88, 20, 1, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>[[460, 598, 497, 390, 286, 138, 73, 18, 7, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>[[785, 856, 803, 635, 417, 167, 66, 11, 5, 4, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>[[925, 932, 829, 570, 389, 156, 57, 7, 5, 1, 0...</td>\n",
       "      <td>3</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>[[704, 728, 594, 521, 396, 179, 39, 15, 1, 0, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                               maps  \\\n",
       "0  blues.00000.wav  [[575, 636, 546, 386, 302, 179, 88, 20, 1, 0, ...   \n",
       "1  blues.00000.wav  [[460, 598, 497, 390, 286, 138, 73, 18, 7, 1, ...   \n",
       "2  blues.00000.wav  [[785, 856, 803, 635, 417, 167, 66, 11, 5, 4, ...   \n",
       "3  blues.00000.wav  [[925, 932, 829, 570, 389, 156, 57, 7, 5, 1, 0...   \n",
       "4  blues.00000.wav  [[704, 728, 594, 521, 396, 179, 39, 15, 1, 0, ...   \n",
       "\n",
       "   split_id  genre  \n",
       "0         0  blues  \n",
       "1         1  blues  \n",
       "2         2  blues  \n",
       "3         3  blues  \n",
       "4         4  blues  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(df.iloc[0,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disco', 'metal', 'pop', 'blues', 'rock', 'hiphop', 'country', 'jazz', 'classical', 'reggae'}\n"
     ]
    }
   ],
   "source": [
    "label_names = set([genre for genre in df['genre']])\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = dict((name, index) for index, name in enumerate(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "for indx, row in df.iterrows():\n",
    "    samples.append(np.array(row['maps']))\n",
    "    labels.append(label_to_idx[row['genre']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices((samples, labels))\n",
    "dataset = dataset.shuffle(128).batch(14)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 10, 12)        444       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 5, 5, 12)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 6)           654       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                70        \n",
      "=================================================================\n",
      "Total params: 1,168\n",
      "Trainable params: 1,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, AveragePooling2D, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(12,(6,6),activation='tanh',input_shape=(15,15,1)))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Conv2D(6,(3,3),activation='tanh'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 15, 15)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "sample_batch, label_batch = next(iter(dataset))\n",
    "print(sample_batch.shape)\n",
    "print(label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7030348777770996, Accuracy: 0.0\n",
      "Loss: 2.5831446647644043, Accuracy: 0.0\n",
      "Loss: 2.476724624633789, Accuracy: 0.0\n",
      "Loss: 2.3755111694335938, Accuracy: 0.0\n",
      "Loss: 2.275522232055664, Accuracy: 0.0\n",
      "Loss: 2.177595853805542, Accuracy: 0.0\n",
      "Loss: 2.074129104614258, Accuracy: 0.0\n",
      "Loss: 1.9780550003051758, Accuracy: 0.0\n",
      "Loss: 1.8935099840164185, Accuracy: 0.1428571492433548\n",
      "Loss: 1.8107675313949585, Accuracy: 0.5714285969734192\n",
      "Loss: 1.7369872331619263, Accuracy: 0.9285714030265808\n",
      "Loss: 1.6774989366531372, Accuracy: 1.0\n",
      "Loss: 1.6287097930908203, Accuracy: 1.0\n",
      "Loss: 1.585117220878601, Accuracy: 1.0\n",
      "Loss: 1.546743392944336, Accuracy: 1.0\n",
      "Loss: 1.5137099027633667, Accuracy: 1.0\n",
      "Loss: 1.4860759973526, Accuracy: 1.0\n",
      "Loss: 1.4615470170974731, Accuracy: 1.0\n",
      "Loss: 1.4381020069122314, Accuracy: 1.0\n",
      "Loss: 1.415238380432129, Accuracy: 1.0\n",
      "Loss: 1.3967764377593994, Accuracy: 1.0\n",
      "Loss: 1.377420425415039, Accuracy: 1.0\n",
      "Loss: 1.3592694997787476, Accuracy: 1.0\n",
      "Loss: 1.3410521745681763, Accuracy: 1.0\n",
      "Loss: 1.3239465951919556, Accuracy: 1.0\n",
      "Loss: 1.3067597150802612, Accuracy: 1.0\n",
      "Loss: 1.290395736694336, Accuracy: 1.0\n",
      "Loss: 1.2740774154663086, Accuracy: 1.0\n",
      "Loss: 1.2580629587173462, Accuracy: 1.0\n",
      "Loss: 1.2415903806686401, Accuracy: 1.0\n",
      "Loss: 1.2265113592147827, Accuracy: 1.0\n",
      "Loss: 1.2115144729614258, Accuracy: 1.0\n",
      "Loss: 1.1977158784866333, Accuracy: 1.0\n",
      "Loss: 1.1841299533843994, Accuracy: 1.0\n",
      "Loss: 1.1711502075195312, Accuracy: 1.0\n",
      "Loss: 1.1582261323928833, Accuracy: 1.0\n",
      "Loss: 1.145453691482544, Accuracy: 1.0\n",
      "Loss: 1.1333321332931519, Accuracy: 1.0\n",
      "Loss: 1.1212939023971558, Accuracy: 1.0\n",
      "Loss: 1.1095483303070068, Accuracy: 1.0\n",
      "Loss: 1.0980913639068604, Accuracy: 1.0\n",
      "Loss: 1.087004542350769, Accuracy: 1.0\n",
      "Loss: 1.0760911703109741, Accuracy: 1.0\n",
      "Loss: 1.0654493570327759, Accuracy: 1.0\n",
      "Loss: 1.0550020933151245, Accuracy: 1.0\n",
      "Loss: 1.0447005033493042, Accuracy: 1.0\n",
      "Loss: 1.0345715284347534, Accuracy: 1.0\n",
      "Loss: 1.024565577507019, Accuracy: 1.0\n",
      "Loss: 1.0146644115447998, Accuracy: 1.0\n",
      "Loss: 1.0048834085464478, Accuracy: 1.0\n",
      "Loss: 0.9951934218406677, Accuracy: 1.0\n",
      "Loss: 0.9855734705924988, Accuracy: 1.0\n",
      "Loss: 0.9760909080505371, Accuracy: 1.0\n",
      "Loss: 0.9667544960975647, Accuracy: 1.0\n",
      "Loss: 0.95753413438797, Accuracy: 1.0\n",
      "Loss: 0.9483975172042847, Accuracy: 1.0\n",
      "Loss: 0.9393649697303772, Accuracy: 1.0\n",
      "Loss: 0.9304173588752747, Accuracy: 1.0\n",
      "Loss: 0.9216023683547974, Accuracy: 1.0\n",
      "Loss: 0.9128720164299011, Accuracy: 1.0\n",
      "Loss: 0.9042295813560486, Accuracy: 1.0\n",
      "Loss: 0.8956718444824219, Accuracy: 1.0\n",
      "Loss: 0.8872073888778687, Accuracy: 1.0\n",
      "Loss: 0.8788520097732544, Accuracy: 1.0\n",
      "Loss: 0.8705925345420837, Accuracy: 1.0\n",
      "Loss: 0.86241215467453, Accuracy: 1.0\n",
      "Loss: 0.8543277978897095, Accuracy: 1.0\n",
      "Loss: 0.8463281989097595, Accuracy: 1.0\n",
      "Loss: 0.8384007811546326, Accuracy: 1.0\n",
      "Loss: 0.8305792808532715, Accuracy: 1.0\n",
      "Loss: 0.8228358030319214, Accuracy: 1.0\n",
      "Loss: 0.8151751756668091, Accuracy: 1.0\n",
      "Loss: 0.8075913786888123, Accuracy: 1.0\n",
      "Loss: 0.8000811338424683, Accuracy: 1.0\n",
      "Loss: 0.7926589250564575, Accuracy: 1.0\n",
      "Loss: 0.7852968573570251, Accuracy: 1.0\n",
      "Loss: 0.7780153155326843, Accuracy: 1.0\n",
      "Loss: 0.7708139419555664, Accuracy: 1.0\n",
      "Loss: 0.763702392578125, Accuracy: 1.0\n",
      "Loss: 0.7566618919372559, Accuracy: 1.0\n",
      "Loss: 0.7497132420539856, Accuracy: 1.0\n",
      "Loss: 0.7428321242332458, Accuracy: 1.0\n",
      "Loss: 0.7360284924507141, Accuracy: 1.0\n",
      "Loss: 0.72929847240448, Accuracy: 1.0\n",
      "Loss: 0.7226367592811584, Accuracy: 1.0\n",
      "Loss: 0.7160457372665405, Accuracy: 1.0\n",
      "Loss: 0.7095304131507874, Accuracy: 1.0\n",
      "Loss: 0.7030846476554871, Accuracy: 1.0\n",
      "Loss: 0.6967045664787292, Accuracy: 1.0\n",
      "Loss: 0.6903930306434631, Accuracy: 1.0\n",
      "Loss: 0.6841496825218201, Accuracy: 1.0\n",
      "Loss: 0.6779718399047852, Accuracy: 1.0\n",
      "Loss: 0.6718559861183167, Accuracy: 1.0\n",
      "Loss: 0.6658092141151428, Accuracy: 1.0\n",
      "Loss: 0.659828245639801, Accuracy: 1.0\n",
      "Loss: 0.6539067625999451, Accuracy: 1.0\n",
      "Loss: 0.6480535864830017, Accuracy: 1.0\n",
      "Loss: 0.6422669291496277, Accuracy: 1.0\n",
      "Loss: 0.6365403532981873, Accuracy: 1.0\n",
      "Loss: 0.6308721899986267, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    metrics = model.train_on_batch(tf.reshape(sample_batch,[14,15,15,1]), label_batch)\n",
    "    if(i % 10==0):\n",
    "        print(\"Loss: {}, Accuracy: {}\".format(metrics[0], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emotion_detection]",
   "language": "python",
   "name": "conda-env-emotion_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
